{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict  \n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import faiss\n",
    "import os, math, warnings, math, pickle\n",
    "\n",
    "path = './data/raw/'\n",
    "generate = './data/generate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_click_df=pd.read_csv(generate+'YGQ.csv')\n",
    "\n",
    "item_info_df=pd.read_csv(path+'articles.csv')\n",
    "item_info_df.rename(columns={'article_id': 'click_article_id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用Embedding的方式获取u2u的相似性矩阵\n",
    "# topk指的是每个user, faiss搜索后返回最相似的topk个user\n",
    "def u2u_embdding_sim(click_df, user_emb_dict, save_path, topk):\n",
    "    \n",
    "    user_list = []\n",
    "    user_emb_list = []\n",
    "    for user_id, user_emb in user_emb_dict.items():\n",
    "        user_list.append(user_id)\n",
    "        user_emb_list.append(user_emb)\n",
    "        \n",
    "    user_index_2_rawid_dict = {k: v for k, v in zip(range(len(user_list)), user_list)}    \n",
    "    \n",
    "    user_emb_np = np.array(user_emb_list, dtype=np.float32)\n",
    "    \n",
    "    # 建立faiss索引\n",
    "    user_index = faiss.IndexFlatIP(user_emb_np.shape[1])\n",
    "    user_index.add(user_emb_np)\n",
    "    # 相似度查询，给每个索引位置上的向量返回topk个item以及相似度\n",
    "    sim, idx = user_index.search(user_emb_np, topk) # 返回的是列表\n",
    "   \n",
    "    # 将向量检索的结果保存成原始id的对应关系\n",
    "    user_sim_dict = collections.defaultdict(dict)\n",
    "    for target_idx, sim_value_list, rele_idx_list in tqdm(zip(range(len(user_emb_np)), sim, idx)):\n",
    "        target_raw_id = user_index_2_rawid_dict[target_idx]\n",
    "        # 从1开始是为了去掉商品本身, 所以最终获得的相似商品只有topk-1\n",
    "        for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1:]): \n",
    "            rele_raw_id = user_index_2_rawid_dict[rele_idx]\n",
    "            user_sim_dict[target_raw_id][rele_raw_id] = user_sim_dict.get(target_raw_id, {}).get(rele_raw_id, 0) + sim_value\n",
    "    \n",
    "    # 保存i2i相似度矩阵\n",
    "    pickle.dump(user_sim_dict, open(save_path + 'youtube_u2u_sim.pkl', 'wb'))   \n",
    "    return user_sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:00, 23820.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# 读取YoutubeDNN过程中产生的user embedding, 然后使用faiss计算用户之间的相似度\n",
    "# 这里需要注意，这里得到的user embedding其实并不是很好，因为YoutubeDNN中使用的是用户点击序列来训练的user embedding,\n",
    "# 如果序列普遍都比较短的话，其实效果并不是很好\n",
    "user_emb_dict = pickle.load(open(generate + 'user_youtube_emb.pkl', 'rb'))\n",
    "u2u_sim = u2u_embdding_sim(all_click_df, user_emb_dict, generate, topk=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
