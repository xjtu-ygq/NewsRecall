{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import collections\n",
    "from collections import defaultdict  \n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import os, math, warnings, math, pickle\n",
    "\n",
    "path = './data/raw/'\n",
    "generate = './data/generate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_click_df=pd.read_csv(generate+'YGQ.csv')\n",
    "\n",
    "item_info_df=pd.read_csv(path+'articles.csv')\n",
    "item_info_df.rename(columns={'article_id': 'click_article_id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 向量检索相似度计算\n",
    "# topk指的是每个item, faiss搜索后返回最相似的topk个item\n",
    "def embdding_sim(click_df, item_emb_df, save_path, topk):\n",
    "    \"\"\"\n",
    "        基于内容的文章embedding相似性矩阵计算\n",
    "        :param click_df: 数据表\n",
    "        :param item_emb_df: 文章的embedding\n",
    "        :param save_path: 保存路径\n",
    "        :patam topk: 找最相似的topk篇\n",
    "        return 文章相似性矩阵\n",
    "        \n",
    "        思路: 对于每一篇文章， 基于embedding的相似性返回topk个与其最相似的文章， 只不过由于文章数量太多，这里用了faiss进行加速\n",
    "    \"\"\"\n",
    "    # 文章索引与文章id的字典映射\n",
    "    item_idx_2_rawid_dict = dict(zip(item_emb_df.index, item_emb_df['article_id']))\n",
    "    \n",
    "    item_emb_cols = [x for x in item_emb_df.columns if 'emb' in x]\n",
    "    item_emb_np = np.ascontiguousarray(item_emb_df[item_emb_cols].values, dtype=np.float32)\n",
    "    # 向量进行单位化\n",
    "    item_emb_np = item_emb_np / np.linalg.norm(item_emb_np, axis=1, keepdims=True)\n",
    "    \n",
    "    # 建立faiss索引\n",
    "    item_index = faiss.IndexFlatIP(item_emb_np.shape[1])\n",
    "    item_index.add(item_emb_np)\n",
    "    # 相似度查询，给每个索引位置上的向量返回topk个item以及相似度\n",
    "    sim, idx = item_index.search(item_emb_np, topk) # 返回的是列表\n",
    "    \n",
    "    # 将向量检索的结果保存成原始id的对应关系\n",
    "    item_sim_dict = collections.defaultdict(dict)\n",
    "    for target_idx, sim_value_list, rele_idx_list in tqdm(zip(range(len(item_emb_np)), sim, idx)):\n",
    "        target_raw_id = item_idx_2_rawid_dict[target_idx]\n",
    "        # 从1开始是为了去掉商品本身, 所以最终获得的相似商品只有topk-1\n",
    "        for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1:]): \n",
    "            rele_raw_id = item_idx_2_rawid_dict[rele_idx]\n",
    "            item_sim_dict[target_raw_id][rele_raw_id] = item_sim_dict.get(target_raw_id, {}).get(rele_raw_id, 0) + sim_value\n",
    "    \n",
    "    # 保存i2i相似度矩阵\n",
    "    pickle.dump(item_sim_dict, open(generate + 'emb_i2i_sim.pkl', 'wb'))   \n",
    "    \n",
    "    return item_sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "364047it [00:14, 25084.50it/s]\n"
     ]
    }
   ],
   "source": [
    "item_emb_df = pd.read_csv(path + 'articles_emb.csv')\n",
    "emb_i2i_sim = embdding_sim(all_click_df, item_emb_df, generate, topk=10) # topk可以自行设置"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
